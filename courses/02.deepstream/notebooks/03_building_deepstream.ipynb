{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the input video path to an environment variable\n",
    "os.environ['TARGET_VIDEO_PATH']='data/<<>>.h264'\n",
    "os.environ['TARGET_VIDEO_PATH_MP4']='<<>>.mp4'\n",
    "\n",
    "target_video_path=os.environ['TARGET_VIDEO_PATH']\n",
    "target_video_path_mp4=os.environ['TARGET_VIDEO_PATH_MP4']\n",
    "\n",
    "# Analyze video\n",
    "!ffprobe -i $TARGET_VIDEO_PATH \\\n",
    "         -hide_banner\n",
    "!ffprobe -i $TARGET_VIDEO_PATH_MP4 \\\n",
    "         -hide_banner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# Convert the H.264 encoded video file to MP4 container file - this will generate the sample_30.mp4 file\n",
    "!ffmpeg -i $TARGET_VIDEO_PATH $TARGET_VIDEO_PATH_MP4 -y -loglevel quiet\n",
    "\n",
    "# View the input video\n",
    "Video(target_video_path_mp4, width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c91495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NGC_DIR']='/dli/task/ngc_assets'\n",
    "os.environ['CLI']='ngccli_linux.zip'\n",
    "\n",
    "# Remove previous versions of NGC CLI, copy, and install NGC CLI\n",
    "!rm -r $NGC_DIR/ngccli/*\n",
    "!cp /dli/task/$CLI $NGC_DIR/ngccli/$CLI\n",
    "!unzip -u \"$NGC_DIR/ngccli/$CLI\" \\\n",
    "       -d $NGC_DIR/ngccli/\n",
    "!rm $NGC_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"NGC_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model download-version nvidia/tao/trafficcamnet:pruned_v1.0 --dest $NGC_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29378a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary GStreamer libraries and DeepStream python bindings\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0') # gst-launch-1.0\n",
    "from gi.repository import GObject, Gst, GLib\n",
    "import pyds\n",
    "\n",
    "# Initialize GStreamer\n",
    "Gst.init(None)\n",
    "\n",
    "# Create Pipeline element that will form a connection of other elements\n",
    "pipeline=Gst.Pipeline()\n",
    "print('Created pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Source element for reading from a file and set the location property\n",
    "source=Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
    "source.set_property('location', target_video_path)\n",
    "\n",
    "# Create H264 Parser with h264parse as the input file is an elementary h264 stream\n",
    "h264parser=Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
    "\n",
    "# Create Decoder with nvv4l2decoder for accelerated decoding on GPU\n",
    "decoder=Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "\n",
    "# Create Streamux with nvstreammux to form batches for one or more sources and set properties\n",
    "streammux=Gst.ElementFactory.make(\"nvstreammux\", \"stream-muxer\")\n",
    "streammux.set_property('width', 888) \n",
    "streammux.set_property('height', 696) \n",
    "streammux.set_property('batch-size', 1)\n",
    "\n",
    "# Create Primary GStreamer Inference Element with nvinfer to run inference on the decoder's output after batching\n",
    "pgie=Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
    "\n",
    "# Create Sink with fakesink as the end point of the pipeline\n",
    "fakesink=Gst.ElementFactory.make('fakesink', 'fakesink')\n",
    "fakesink.set_property('sync', 1)\n",
    "print('Created elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add elements to pipeline\n",
    "pipeline.add(source)\n",
    "pipeline.add(h264parser)\n",
    "pipeline.add(decoder)\n",
    "pipeline.add(streammux)\n",
    "pipeline.add(pgie)\n",
    "pipeline.add(fakesink)\n",
    "print('Added elements to pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c72a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat spec_files/pgie_config_trafficcamnet_03.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configuration-file-path property for nvinfer\n",
    "pgie.set_property('config-file-path', '/dli/task/spec_files/pgie_config_trafficcamnet_03.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link elements in the pipeline\n",
    "source.link(h264parser)\n",
    "h264parser.link(decoder)\n",
    "\n",
    "# Link decoder source pad to streammux sink pad\n",
    "decoder_srcpad=decoder.get_static_pad(\"src\")    \n",
    "streammux_sinkpad=streammux.get_request_pad(\"sink_0\")\n",
    "decoder_srcpad.link(streammux_sinkpad)\n",
    "\n",
    "# Link the rest of the elements in the pipeline\n",
    "streammux.link(pgie)\n",
    "pgie.link(fakesink)\n",
    "print('Linked elements in pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare list to hold count data\n",
    "obj_counts=[]\n",
    "\n",
    "# Define the Probe Function\n",
    "def pgie_src_pad_buffer_probe(pad, info):\n",
    "    gst_buffer=info.get_buffer()\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    # Note that pyds.gst_buffer_get_nvds_batch_meta() expects the\n",
    "    # C address of gst_buffer as input, which is obtained with hash(gst_buffer)\n",
    "    batch_meta=pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame=batch_meta.frame_meta_list\n",
    "    \n",
    "    # Iterate through each frame in the batch metadata until the end\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            frame_meta=pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        frame_num=frame_meta.frame_num\n",
    "        num_obj=frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        print(\"Frame Number={} Number of Objects={}\".format(frame_num, num_obj))\n",
    "        \n",
    "        # Append number of objects a list \n",
    "        obj_counts.append(num_obj)\n",
    "        \n",
    "        # Iterate through each object in the frame metadata until the end\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "                print('\\t Object: {} - Top: {}, Left: {}, Width: {}, Height: {}'.format(obj_meta.obj_label, \\\n",
    "                                                                                        round(obj_meta.rect_params.top), \\\n",
    "                                                                                        round(obj_meta.rect_params.left), \\\n",
    "                                                                                        round(obj_meta.rect_params.width), \\\n",
    "                                                                                        round(obj_meta.rect_params.height)))\n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155dd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add probe to inference plugin's source\n",
    "pgie_src_pad=pgie.get_static_pad('src')\n",
    "probe_id=pgie_src_pad.add_probe(Gst.PadProbeType.BUFFER, pgie_src_pad_buffer_probe)\n",
    "print('Attached probe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b285d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.bus_call import bus_call\n",
    "\n",
    "# Inspect the definition for bus_call\n",
    "from inspect import getsource\n",
    "print(getsource(bus_call))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ee0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an event loop\n",
    "loop=GLib.MainLoop()\n",
    "\n",
    "# Feed GStreamer bus messages to loop\n",
    "bus=pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "print('Added bus message handler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e10491",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start play back and listen to events\n",
    "print(\"Starting pipeline\")\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Cleaning up as the pipeline comes to an end\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Export data to a Pandas Series\n",
    "obj_count_df=pd.Series(obj_counts, name='Object Count')\n",
    "obj_count_df.index.name='Frame Number'\n",
    "\n",
    "# Plot the Series\n",
    "obj_count_df.plot(\n",
    "    linestyle='none', \n",
    "    marker='.', \n",
    "    figsize=(15, 5), \n",
    "    ylim=[-.1, 3.1], \n",
    "    title='Object Count Over Time'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a950b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import app_3_pt_1.py from sample_apps directory\n",
    "import sample_apps.app_3_pt_1\n",
    "\n",
    "# Print the docstring \n",
    "print(sample_apps.app_3_pt_1.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfab627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_apps.app_3_pt_1 import build_simple_pipeline\n",
    "\n",
    "# Print the docstring\n",
    "print(build_simple_pipeline.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afe9c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test run the Python script\n",
    "!python sample_apps/app_3_pt_1.py data/sample_30.h264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "frame_rates=[]\n",
    "\n",
    "# Define the Probe Function\n",
    "def pgie_src_pad_buffer_probe_fps(pad, info):\n",
    "    global start\n",
    "    frame_number=0\n",
    "    gst_buffer=info.get_buffer()\n",
    "    \n",
    "    batch_meta=pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame=batch_meta.frame_meta_list\n",
    "    \n",
    "    # Iterate through each frame in the batch metadata until the end\n",
    "    while l_frame is not None:\n",
    "        now=time.time()\n",
    "        try:\n",
    "            frame_meta=pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        frame_number=frame_meta.frame_num\n",
    "        \n",
    "        # Take the reciprocal of the time difference as frame rate\n",
    "        frame_rate=round(1/(now-start), 2)\n",
    "        print('FPS: {} @ Frame {}.'.format(frame_rate, frame_number))\n",
    "        \n",
    "        # Add frame rate to frame_rates list\n",
    "        frame_rates.append(frame_rate)\n",
    "        \n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "        start=now\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard GStreamer initialization\n",
    "Gst.init(None)\n",
    "\n",
    "# Build pipeline\n",
    "pipeline=build_simple_pipeline('data/sample_30.h264')\n",
    "print('Successfully created a {} object'.format(type(pipeline)))\n",
    "\n",
    "# Get the nvinfer plugin by name\n",
    "pgie=pipeline.get_by_name('primary-inference')\n",
    "\n",
    "# Add probe to inference plugin's source\n",
    "pgie_src_pad=pgie.get_static_pad('src')\n",
    "pgie_src_pad.add_probe(Gst.PadProbeType.BUFFER, pgie_src_pad_buffer_probe_fps)\n",
    "print('Attached Probe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MainLoop and add a signal watch\n",
    "loop=GLib.MainLoop()\n",
    "bus=pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "print('Added bus message handler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c98e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start Pipeline\n",
    "print(\"Starting pipeline\")\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "start=time.time()\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Cleaning up as the pipeline comes to an end\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6017e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to a Pandas Series\n",
    "frame_rates_df=pd.Series(frame_rates, name='Frame Rate')\n",
    "frame_rates_df.index.name='Frame Number'\n",
    "\n",
    "# Plot the Series\n",
    "frame_rates_df.plot(\n",
    "    linestyle='none', \n",
    "    marker='.', \n",
    "    figsize=(15, 5), \n",
    "    ylim=[-.1, 50], \n",
    "    title='Frame Rate Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537103c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!GST_DEBUG='GST_SCHEDULING:7' GST_DEBUG_FILE='/dli/task/logs/trace.log' python sample_apps/app_3_pt_1.py data/sample_30.h264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56796b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /dli/task/logs/trace.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a98f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import re\n",
    "\n",
    "trace_log=[]\n",
    "# Column headers per documentation\n",
    "headers=['time_stamp', 'process_id', 'thread_id', 'level', 'category', 'src_file_line', 'function', 'object_name', 'message']\n",
    "\n",
    "# Helper function to remove ANSI escape sequences\n",
    "def escape_ansi(line):\n",
    "    ansi_escape = re.compile(r'(?:\\x1B[@-_]|[\\x80-\\x9F])[0-?]*[ -/]*[@-~]')\n",
    "    return ansi_escape.sub('', line)\n",
    "\n",
    "# Open trace.log\n",
    "with open('/dli/task/logs/trace.log') as f: \n",
    "    # Read file\n",
    "    lines=f.readlines()\n",
    "    # Iterate through each line\n",
    "    for each_line in lines: \n",
    "        # Exclude the last character, which is a newline (\\n) character\n",
    "        current_line=escape_ansi(each_line[:-1])\n",
    "        # Split based on white space(s), keeping in mind that src_file, line, function, and object are concatenated together\n",
    "        time_stamp, process_id, thread_id, level, category, src_file_line_function_object, message=re.split(' +', current_line, maxsplit=6)\n",
    "        # Split src_file, line, function, and object based on the semicolon character\n",
    "        src_file, line, function, object=src_file_line_function_object.split(':', maxsplit=3)\n",
    "        # Add all data to the trace_log list\n",
    "        trace_log.append([time_stamp, process_id, thread_id, level, category, f'{src_file}:{line}', function, object, message])\n",
    "\n",
    "# Export data to a DataFrame\n",
    "df=pd.DataFrame(trace_log, columns=headers)\n",
    "# Preview the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through rows backwards to get the time stamp\n",
    "for idx, row in df[::-1].iterrows(): \n",
    "    # Time stamp is pts if object is a sink\n",
    "    if row['object_name'] in ['<stream-muxer:sink_0>', '<primary-inference:sink>', '<fakesink:sink>']: \n",
    "        try: \n",
    "            df.loc[idx, 'frame_ts']=re.findall('pts \\d+:\\d+:\\d+.\\d+', row['message'])[0].split('pts ')[-1]\n",
    "        except: \n",
    "            pass\n",
    "    # Time stamp is dts if object is a decoder sink\n",
    "    elif row['object_name']=='<nvv4l2-decoder:sink>': \n",
    "        try: \n",
    "            ts=re.findall('dts \\d+:\\d+:\\d+.\\d+', row['message'])[0].split('dts ')[-1]\n",
    "            if ts: \n",
    "                df.loc[idx, 'frame_ts']=ts\n",
    "                decoder_offset=re.findall('offset \\d+', row['message'])[0].split('offset ')[-1]\n",
    "        except: \n",
    "            pass\n",
    "    # Time stamp is same as dts of decoder with same offset for file source\n",
    "    elif row['object_name']=='<file-source:src>':\n",
    "        try: \n",
    "            src_offset=re.findall('offset \\d+', row['message'])[0].split('offset ')[-1]\n",
    "            if src_offset==decoder_offset: \n",
    "                df.loc[idx, 'frame_ts']=ts\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df=df[['time_stamp', 'object_name', 'frame_ts']].dropna().drop_duplicates(subset=['object_name', 'frame_ts'])\n",
    "\n",
    "# Pivot dataframe\n",
    "time_df=time_df.pivot(index='object_name', values='time_stamp', columns='frame_ts')\n",
    "\n",
    "# Leave time stamp as only seconds \n",
    "time_df.columns=[float(each_column.split(':')[2]) for each_column in time_df.columns]\n",
    "\n",
    "# Clean up\n",
    "time_df=time_df.dropna(axis=1)\n",
    "\n",
    "# Display time_df\n",
    "time_df=time_df.sort_values(0.0).applymap(lambda x: float(x.rsplit(':')[2]))\n",
    "print('Time Stamp when Buffer Arrives (seconds)')\n",
    "display(time_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefc0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference as processed time\n",
    "diff_df=-time_df.diff(-1).T\n",
    "\n",
    "# Plot results\n",
    "diff_df.iloc[:, :-1].plot(figsize=(15, 5)).legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6d1c2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi dmon -i 0 \\\n",
    "                 -s ucmt \\\n",
    "                 -c 100 > '/dli/task/logs/smi.log' \\\n",
    "&python sample_apps/app_3_pt_1.py data/sample_30.h264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /dli/task/logs/smi.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb485e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GStreamer\n",
    "Gst.init(None)\n",
    "\n",
    "# Build pipeline\n",
    "pipeline=build_simple_pipeline('data/sample_30.h264')\n",
    "print('Successfully created a {} object'.format(type(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Fakesink\n",
    "fakesink=pipeline.get_by_name('fakesink')\n",
    "pipeline.remove(fakesink)\n",
    "\n",
    "# Create Convertor to convert from YUV to RGBA as required by nvdsosd\n",
    "nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor1\")\n",
    "\n",
    "# Create OSD with nvdsosd to draw on the converted RGBA buffer\n",
    "nvosd=Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
    "\n",
    "# Create Convertor to convert from RGBA to I420 as required by encoder\n",
    "nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
    "\n",
    "# Create Capsfilter to enforce frame image format\n",
    "capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
    "caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
    "capsfilter.set_property(\"caps\", caps)\n",
    "\n",
    "# Create Encoder to encode I420 formatted frames using the MPEG4 codec\n",
    "encoder = Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
    "encoder.set_property(\"bitrate\", 2000000)\n",
    "\n",
    "# Create Sink and set the location for the output file\n",
    "filesink=Gst.ElementFactory.make('filesink', 'filesink')\n",
    "filesink.set_property('location', 'output_03_encoded.mpeg4')\n",
    "filesink.set_property(\"sync\", 1)\n",
    "print('Created elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e482d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add elements to pipeline\n",
    "pipeline.add(nvvidconv1)\n",
    "pipeline.add(nvosd)\n",
    "pipeline.add(nvvidconv2)\n",
    "pipeline.add(capsfilter)\n",
    "pipeline.add(encoder)\n",
    "pipeline.add(filesink)\n",
    "print('Added elements to pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nvinfer plugin by name\n",
    "pgie=pipeline.get_by_name('primary-inference')\n",
    "\n",
    "# Link elements together\n",
    "pgie.link(nvvidconv1)\n",
    "nvvidconv1.link(nvosd)\n",
    "nvosd.link(nvvidconv2)\n",
    "nvvidconv2.link(capsfilter)\n",
    "capsfilter.link(encoder)\n",
    "encoder.link(filesink)\n",
    "print('Linked elements in pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13241a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# Define the Probe Function\n",
    "def osd_sink_pad_buffer_probe(pad, info):\n",
    "    gst_buffer=info.get_buffer()\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    # Note that pyds.gst_buffer_get_nvds_batch_meta() expects the\n",
    "    # C address of gst_buffer as input, which is obtained with hash(gst_buffer)\n",
    "    batch_meta=pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame=batch_meta.frame_meta_list\n",
    "\n",
    "    # Iterate through each frame in the batch metadata until the end\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            frame_meta=pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        frame_number=frame_meta.frame_num\n",
    "        num_rects=frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        # Iterate through each object in the frame metadata until the end\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            # Set border color (red, green, blue, alpha) to random values\n",
    "            obj_meta.rect_params.border_color.set(random(), random(), random(), random())\n",
    "            \n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "        # Acquire display metadata from pool and set number of labels to 1\n",
    "        display_meta=pyds.nvds_acquire_display_meta_from_pool(batch_meta)\n",
    "        display_meta.num_labels=1\n",
    "        \n",
    "        # Set text_params of the display metadata to local variable\n",
    "        py_nvosd_text_params=display_meta.text_params[0]\n",
    "\n",
    "        # Setting display text to be shown on screen\n",
    "        py_nvosd_text_params.display_text=\"Frame Number={} Number of Objects={}\".format(frame_number, num_rects)\n",
    "\n",
    "        # Use pyds.get_string() to get display_text as string\n",
    "        # Reading the display_text field here will return the C address of the\n",
    "        # allocated string. Use pyds.get_string() to get the string content.\n",
    "        print(pyds.get_string(py_nvosd_text_params.display_text))\n",
    "        \n",
    "        # Set the offsets where the string should appear\n",
    "        py_nvosd_text_params.x_offset=10\n",
    "        py_nvosd_text_params.y_offset=10\n",
    "\n",
    "        # Set font, font-color (red, green, blue, alpha), and font-size\n",
    "        py_nvosd_text_params.font_params.font_name=\"Serif\"\n",
    "        py_nvosd_text_params.font_params.font_size=15\n",
    "        py_nvosd_text_params.font_params.font_color.set(1.0, 1.0, 1.0, 1.0)\n",
    "\n",
    "        # Set text background color (red, green, blue, alpha)\n",
    "        py_nvosd_text_params.set_bg_clr=1\n",
    "        py_nvosd_text_params.text_bg_clr.set(0.0, 0.0, 0.0, 1.0)\n",
    "\n",
    "        # Add to frame metadata\n",
    "        pyds.nvds_add_display_meta_to_frame(frame_meta, display_meta)\n",
    "\n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6630d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add probe to nvdsosd plugin's sink\n",
    "osdsinkpad=nvosd.get_static_pad(\"sink\")\n",
    "probe_id=osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe)\n",
    "print('Attached probe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an event loop\n",
    "loop=GLib.MainLoop()\n",
    "\n",
    "# Feed GStreamer bus messages to loop\n",
    "bus=pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect(\"message\", bus_call, loop)\n",
    "print('Added bus message handler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3225d75",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start play back and listen to events - this will generate the output_03_raw.mpeg4 file\n",
    "print(\"Starting pipeline\")\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Cleaning up as the pipeline comes to an end\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d435c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MPEG4 video file to MP4 container file\n",
    "!ffmpeg -i /dli/task/output_03_encoded.mpeg4 /dli/task/output_03.mp4 -y -loglevel quiet\n",
    "\n",
    "# View the output video\n",
    "Video(\"output_03.mp4\", width=720)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
