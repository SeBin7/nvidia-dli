{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the input video path to an environment variable\n",
    "os.environ['TARGET_VIDEO_PATH']='data/sample_30.h264'\n",
    "os.environ['TARGET_VIDEO_PATH_MP4']='sample_30.mp4'\n",
    "\n",
    "target_video_path=os.environ['TARGET_VIDEO_PATH']\n",
    "target_video_path_mp4=os.environ['TARGET_VIDEO_PATH_MP4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6945272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# Convert the H.264 encoded video file to MP4 container file - this will generate the sample_30.mp4 file\n",
    "!ffmpeg -i $TARGET_VIDEO_PATH $TARGET_VIDEO_PATH_MP4 -y -loglevel quiet\n",
    "\n",
    "# View the input video\n",
    "Video(target_video_path_mp4, width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1447e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NGC_DIR']='/dli/task/ngc_assets'\n",
    "os.environ['CLI']='ngccli_linux.zip'\n",
    "\n",
    "# Remove previous versions of NGC CLI, copy, and install NGC CLI\n",
    "!rm -r $NGC_DIR/ngccli/*\n",
    "!cp /dli/task/$CLI $NGC_DIR/ngccli/$CLI\n",
    "!unzip -u \"$NGC_DIR/ngccli/$CLI\" \\\n",
    "       -d $NGC_DIR/ngccli/\n",
    "!rm $NGC_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"NGC_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba3e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the purpose-built TrafficCamNet model from NGC\n",
    "!ngc registry model download-version nvidia/tao/<<<<FIXME>>>> --dest $NGC_DIR\n",
    "\n",
    "# Download the purpose-built VehicleTypeNet model from NGC\n",
    "!ngc registry model download-version nvidia/tao/<<<<FIXME>>>> --dest $NGC_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60338940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary GStreamer libraries and DeepStream python bindings\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, Gst, GLib\n",
    "from common.bus_call import bus_call\n",
    "import pyds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89562c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize GStreamer\n",
    "Gst.<<<<FIXME>>>>\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline=<<<<FIXME>>>>\n",
    "print('Created pipeline')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "413efd96-894d-42db-965e-3665fdb3e782",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Gst.init(None)\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline=Gst.Pipeline()\n",
    "print('Created pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063dacf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Source element for reading from a file and set the location property\n",
    "source = Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
    "source.set_property('location', \"data/sample_30.h264\")\n",
    "\n",
    "# Create H264 Parser with h264parse as the input file is an elementary h264 stream\n",
    "h264parser = Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
    "\n",
    "# Create Decoder with nvv4l2decoder for accelerating decoding on GPU\n",
    "decoder = Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "\n",
    "# Create Streamux with nvstreammux to form batches for one or more sources and set properties\n",
    "streammux = Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
    "streammux.set_property('width', 888) \n",
    "streammux.set_property('height', 696) \n",
    "streammux.set_property('batch-size', 1)\n",
    "\n",
    "# Create Primary GStreamer Inference Element with nvinfer to run inference on the decoder's output after batching\n",
    "pgie=Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
    "\n",
    "# Create Secondary Inference Element with nvinfer to run inference on the pgie's output\n",
    "sgie=<<<<FIXME>>>>\n",
    "\n",
    "# Create Convertor to convert from YUV to RGBA as required by nvdsosd\n",
    "nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor1\")\n",
    "\n",
    "# Create OSD with nvdsosd to draw on the converted RGBA buffer\n",
    "nvosd=Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
    "\n",
    "# Create Convertor to convert from RGBA to I420 as required by encoder\n",
    "nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
    "\n",
    "# Create Capsfilter to enforce frame image format\n",
    "capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
    "caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
    "capsfilter.set_property(\"caps\", caps)\n",
    "\n",
    "# Create Encoder to encode I420 formatted frames using the MPEG4 codec\n",
    "encoder=Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
    "encoder.set_property(\"bitrate\", 2000000)\n",
    "\n",
    "# Create Sink with fakesink as the end point of the pipeline\n",
    "sink=Gst.ElementFactory.make('filesink', 'filesink')\n",
    "sink.set_property('location', 'output_04_raw.mpeg4')\n",
    "sink.set_property(\"sync\", 1)\n",
    "print('Created elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f57a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add elements to pipeline\n",
    "pipeline.add(source)\n",
    "pipeline.add(h264parser)\n",
    "pipeline.add(decoder)\n",
    "pipeline.add(streammux)\n",
    "pipeline.add(pgie)\n",
    "pipeline.add(sgie)\n",
    "pipeline.add(nvvidconv1)\n",
    "pipeline.add(nvosd)\n",
    "pipeline.add(nvvidconv2)\n",
    "pipeline.add(capsfilter)\n",
    "pipeline.add(encoder)\n",
    "pipeline.add(sink)\n",
    "print('Added elements to pipeline')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9aa55a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "!cat spec_files/sgie_config_vehicletypenet_04_soln.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4eabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of the config file\n",
    "pgie.set_property('config-file-path', 'spec_files/pgie_config_trafficcamnet_04.txt')\n",
    "\n",
    "sgie.set_property('config-file-path', 'spec_files/sgie_config_vehicletypenet_04.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the labels\n",
    "!cat ngc_assets/vehicletypenet_vpruned_v1.0/labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68558aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Link elements together\n",
    "source.link(h264parser)\n",
    "h264parser.link(decoder)\n",
    "\n",
    "# Link decoder source pad to streammux sink pad\n",
    "decoder_srcpad=decoder.get_static_pad(\"src\")    \n",
    "streammux_sinkpad=streammux.get_request_pad(\"sink_0\")\n",
    "decoder_srcpad.link(streammux_sinkpad)\n",
    "\n",
    "# Link the rest of the elements in the pipeline\n",
    "streammux.link(pgie)\n",
    "pgie.<<<<FIXME>>>>\n",
    "<<<<FIXME>>>>.link(nvvidconv1)\n",
    "nvvidconv1.link(nvosd)\n",
    "nvosd.link(nvvidconv2)\n",
    "nvvidconv2.link(capsfilter)\n",
    "capsfilter.link(encoder)\n",
    "encoder.link(sink)\n",
    "print('Linked elements in pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Probe Function\n",
    "def osd_sink_pad_buffer_probe(pad, info):\n",
    "    gst_buffer = info.get_buffer()\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    # Note that pyds.gst_buffer_get_nvds_batch_meta() expects the\n",
    "    # C address of gst_buffer as input, which is obtained with hash(gst_buffer)\n",
    "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame = batch_meta.frame_meta_list\n",
    "\n",
    "    # Iterate through each frame in the batch metadata until the end\n",
    "    while l_frame is not None:\n",
    "        try:\n",
    "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        frame_num=frame_meta.frame_num\n",
    "        num_obj = frame_meta.num_obj_meta\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        print(\"Frame Number={} Number of Objects={}\".format(frame_num, num_obj))\n",
    "        \n",
    "        # Iterate through each object in the frame metadata until the end\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "                \n",
    "                # Define an analyze_meta function to manipulate metadata\n",
    "                analyze_meta(obj_meta)\n",
    "            except StopIteration:\n",
    "                break\n",
    "                \n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PGIE_CLASS_ID_CAR=0\n",
    "\n",
    "# Define helper function\n",
    "def analyze_meta(obj_meta): \n",
    "    # Only car supports secondary inference\n",
    "    if obj_meta.class_id == PGIE_CLASS_ID_CAR:     \n",
    "        cls_meta=obj_meta.classifier_meta_list\n",
    "        \n",
    "        # Iterate through each class meta until the end\n",
    "        while cls_meta is not None:\n",
    "            cls=pyds.NvDsClassifierMeta.cast(cls_meta.data)\n",
    "            # Get label info\n",
    "            label_info=cls.label_info_list  \n",
    "            \n",
    "            # Iterate through each label info meta until the end\n",
    "            while label_info is not None:\n",
    "                # Cast data type of label from pyds.GList\n",
    "                label_meta=pyds.glist_get_nvds_label_info(label_info.data)\n",
    "                if cls.unique_component_id==2:\n",
    "                    print('\\t Type & Probability = {}% {}'.format(round(label_meta.result_prob*100), label_meta.result_label))\n",
    "                try:\n",
    "                    label_info=label_info.next\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            \n",
    "            try:\n",
    "                cls_meta=cls_meta.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b9270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add probe to nvdsosd plugin's sink\n",
    "osdsinkpad = nvosd.get_static_pad(\"sink\")\n",
    "osdsinkpad.add_probe(<<<<FIXME>>>>, <<<<FIXME>>>>)\n",
    "print('Attached probe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an event loop\n",
    "loop=GLib.MainLoop()\n",
    "\n",
    "# Feed GStreamer bus messages to loop\n",
    "bus=pipeline.get_bus()\n",
    "bus.add_signal_watch()\n",
    "bus.connect (\"message\", bus_call, loop)\n",
    "print('Added bus message handler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb1f8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Starting pipeline \\n\")\n",
    "pipeline.set_state(<<<<FIXME>>>>)\n",
    "try: \n",
    "    loop.<<<<FIXME>>>>\n",
    "except: \n",
    "    pass\n",
    "\n",
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4d130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert MPEG4 video file to MP4 container file\n",
    "!ffmpeg -i /dli/task/output_04_raw.mpeg4 /dli/task/output_04.mp4 -y -loglevel quiet\n",
    "\n",
    "# View the output video\n",
    "Video(\"output_04.mp4\", width=720)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
