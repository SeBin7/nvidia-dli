{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5c30-81b7-4a34-9789-b59614f44d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and create directories for the TAO Toolkit experiment\n",
    "import os\n",
    "\n",
    "os.environ['PROJECT_DIR']='/dli/task/tao_project'\n",
    "os.environ['SOURCE_DATA_DIR']='/dli/task/data'\n",
    "os.environ['DATA_DIR']='/dli/task/tao_project/data'\n",
    "os.environ['MODELS_DIR']='/dli/task/tao_project/models'\n",
    "os.environ['SPEC_FILES_DIR']='/dli/task/spec_files'\n",
    "\n",
    "!mkdir $PROJECT_DIR\n",
    "!mkdir $DATA_DIR\n",
    "!mkdir $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17627b-9ede-49df-8893-e375e59469bc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NGC_DIR']='/dli/task/ngc_assets'\n",
    "os.environ['CLI']='ngccli_linux.zip'\n",
    "\n",
    "# Remove previous versions of NGC CLI, copy, and install NGC CLI\n",
    "!rm -r $NGC_DIR/ngccli/*\n",
    "!cp /dli/task/$CLI $NGC_DIR/ngccli/$CLI\n",
    "!unzip -u \"$NGC_DIR/ngccli/$CLI\" \\\n",
    "       -d $NGC_DIR/ngccli/\n",
    "!rm $NGC_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"NGC_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d1394b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all available models\n",
    "!ngc registry model list nvidia/tao/* --column name --column repository --column application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the unpruned pre-trained model from NGC\n",
    "!ngc registry model download-version nvidia/tao/trafficcamnet:unpruned_v1.0 \\\n",
    "    --dest $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a7ac2-cf8e-4536-98a0-066dea725ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pruned pre-trained model from NGC\n",
    "!ngc registry model download-version nvidia/tao/trafficcamnet:pruned_v1.0 \\\n",
    "    --dest $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03eafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if models have been downloaded into directory\n",
    "!ls -rlt $MODELS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ad2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the video\n",
    "from IPython.display import Video\n",
    "\n",
    "Video(\"data/126_206-A0-3_raw.mp4\", width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42767e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preview the annotation\n",
    "!cat $SOURCE_DATA_DIR/126_206-A0-3_json_sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .csv into a DataFrame\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "annotated_frames=pd.read_csv('data/annotation.csv', converters={2:ast.literal_eval})\n",
    "print(\"Length of the full DF object:\", len(annotated_frames))\n",
    "annotated_frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rows per frame_no\n",
    "annotated_frames.groupby('frame_no').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out annotations that do not have car inside the bbox\n",
    "filtered_frames=annotated_frames[annotated_frames[\"outside\"] == 0]\n",
    "print(\"Length of the filtered DF object:\", len(filtered_frames))\n",
    "filtered_frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frames that include moving cars\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "frames_list=list(filtered_frames['frame_no'].unique())\n",
    "frame_existance=np.zeros(annotated_frames['frame_no'].max()+1)\n",
    "for i in frames_list:\n",
    "    frame_existance[int(i)]=1\n",
    "y_pos=np.arange(len(frame_existance))\n",
    "fig, ax=plt.subplots(figsize=(18, 3))\n",
    "plt.bar(y_pos, frame_existance, align='center', alpha=0.5)\n",
    "plt.title('Frame Indices that Include Moving Cars')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract images and generate an annotated video\n",
    "import cv2\n",
    "colors = [(255, 255, 0), (255, 0, 255), (0, 255, 255), (0, 0, 255), (255, 0, 0), (0, 255, 0), (0, 0, 0), (255, 100, 0), (100, 255, 0), (100, 0, 255), (255, 0, 100)]\n",
    "\n",
    "def save_images(video_path, image_folder, frames_list, annotated_frames,  video_out_folder, fps=10):\n",
    "    # Create image folder if it doesn't exist\n",
    "    if not os.path.exists(image_folder):\n",
    "        print(\"Creating images folder\")\n",
    "        os.makedirs(image_folder)\n",
    "    \n",
    "    # Create directory for output video\n",
    "    if not os.path.exists(video_out_folder):\n",
    "        print(\"Creating video out folder\")\n",
    "        os.makedirs(video_out_folder)\n",
    "    \n",
    "    # Start reading input video\n",
    "    input_video=cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # cv2.VideoCapture().read() returns true if it has a next frame\n",
    "    retVal, im=input_video.read()\n",
    "    size=im.shape[1], im.shape[0]\n",
    "    fourcc=cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    \n",
    "    # Start writing output video\n",
    "    output_video=cv2.VideoWriter('{}/annotated_video.mp4'.format(video_out_folder), fourcc, fps, size)\n",
    "\n",
    "    frameCount=0\n",
    "    i=1\n",
    "    \n",
    "    # While has next frame\n",
    "    while retVal:\n",
    "        print(\"\\rProcessing frame no: {}\".format(frameCount), end='', flush=True)\n",
    "        \n",
    "        # If current frame is in the list of annotated frames, draw bounding box(es) and include in the output video\n",
    "        if frameCount in frames_list:\n",
    "            print(\"\\rSaving frame no: {}, index: {} out of {}\".format(frameCount, i, len(frames_list)), end='')\n",
    "            cv2.imwrite(os.path.join(image_folder, '{}.png'.format(frameCount)), im)\n",
    "            i+=1\n",
    "            frame_items=annotated_frames[annotated_frames[\"frame_no\"]==int(frameCount)]\n",
    "            for index, box in frame_items.iterrows():\n",
    "                xmin, ymin, xmax, ymax = box[\"xmin\"], box[\"ymin\"], box[\"xmax\"], box[\"ymax\"]\n",
    "                xmin2, ymin2, xmax2, ymax2 = box[\"crop\"][0], box[\"crop\"][1], box[\"crop\"][2], box[\"crop\"][3]\n",
    "                cv2.rectangle(im, (xmin, ymin), (xmax, ymax), colors[0], 1)\n",
    "                cv2.rectangle(im, (int(xmin2), int(ymin2)), (int(xmax2), int(ymax2)), colors[1], 1)\n",
    "            output_video.write(im)\n",
    "\n",
    "        # Read next frame\n",
    "        retVal, im=input_video.read()\n",
    "        frameCount+=1\n",
    "\n",
    "    input_video.release()\n",
    "    output_video.release()\n",
    "    return size        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images and generate an annotated video\n",
    "save_images('{}/126_206-A0-3_raw.mp4'.format(os.environ['SOURCE_DATA_DIR']), \n",
    "            '{}/{}'.format('{}/training'.format(os.environ['DATA_DIR']), 'images'),\n",
    "            frames_list,\n",
    "            filtered_frames,\n",
    "            '{}/{}'.format(os.environ['DATA_DIR'], 'video_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467aae35-f880-46d3-98d4-d75d535dfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the video to a format that is compatible with Jupyter Lab\n",
    "!ffmpeg -i tao_project/data/video_out/annotated_video.mp4 tao_project/data/video_out/annotated_video_conv.mp4 -y -loglevel quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043185ff-923e-4fa4-ba55-346c2fe4ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the annotated output video\n",
    "Video('tao_project/data/video_out/annotated_video_conv.mp4', width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fee05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels in KITTI format\n",
    "label_folder='{}/training/labels'.format(os.environ['DATA_DIR'])\n",
    "if not os.path.exists(label_folder):\n",
    "    print(\"Creating labels folder\")\n",
    "    os.makedirs(label_folder)\n",
    "for frame in sorted(frames_list): \n",
    "    current_frame=filtered_frames[filtered_frames['frame_no']==frame]\n",
    "    with open('{}/{}.txt'.format(label_folder, frame), 'w') as f: \n",
    "        for i, box in current_frame.iterrows(): \n",
    "            print('Writing for frame {}'.format(frame), end='\\r')\n",
    "            f.write(\"Car 0 0 0 {} {} {} {} 0 0 0 0 0 0 0\\n\".format(box['xmin'], box['ymin'], box['xmax'], box['ymax']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview sample KITTI format labels\n",
    "!cat $DATA_DIR/training/labels/20.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e32483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the spec file\n",
    "!cat $SPEC_FILES_DIR/kitti_config.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d50ae69e-924e-4d19-a4df-bdaff60da229",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# kitti_config {\n",
    "#   root_directory_path: \"/dli/task/tao_project/data/training\"\n",
    "#   image_dir_name: \"images\"\n",
    "#   label_dir_name: \"labels\"\n",
    "#   image_extension: \".png\"\n",
    "#   partition_mode: \"random\"\n",
    "#   num_partitions: 2\n",
    "#   val_split: 20\n",
    "#   num_shards: 10\n",
    "# }\n",
    "# image_directory_path: \"/dli/task/tao_project/data/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac87378-6ea2-418c-ae87-922b84c3b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataset_convert usage\n",
    "!detectnet_v2 dataset_convert --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14481bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory for TFRecords and delete existing files if they exist\n",
    "!mkdir -p $DATA_DIR/tfrecords && rm -rf $DATA_DIR/tfrecords/*\n",
    "\n",
    "!detectnet_v2 dataset_convert -d $SPEC_FILES_DIR/kitti_config.txt \\\n",
    "                              -o $DATA_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b2899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the shards that have been created\n",
    "!ls -rlt $DATA_DIR/tfrecords/kitti_trainval/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
